{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8131118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mongodb_lib import *\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from openai_handlers import *\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "634cdb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Successfully connected to MongoDB.\n"
     ]
    }
   ],
   "source": [
    "config_infra = yaml.load(open(\"../infra-config-pipeline.yaml\"), Loader=yaml.FullLoader)\n",
    "db, fs, client = connect_to_mongodb(config_infra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "311e000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import taxonomy\n",
    "\n",
    "taxonomy = pd.read_excel(\"../Categories.xlsx\")\n",
    "taxonomy = taxonomy[[\"Sub-category\", \"Description & Keywords.1\"]]\n",
    "\n",
    "taxonomy_json = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "labels_with_descriptions = list()\n",
    "description2id = {}\n",
    "\n",
    "for key, value in zip(taxonomy[\"Sub-category\"], taxonomy[\"Description & Keywords.1\"]):\n",
    "\n",
    "    entries = value.split(\"\\n\")\n",
    "    assert len(entries) == 2\n",
    "\n",
    "    labels_with_descriptions.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c2428366",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_object(fs, \"product_textual_lang_summarized\")\n",
    "data = pd.DataFrame(data)\n",
    "data.fillna(\"\", inplace=True)\n",
    "data = data[[\"pdt_product_detail_PRODUCTDESCRIPTION_SUMMARIZED\"]]\n",
    "data.columns = [\"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "59693d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "bd41b207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I'm ready to begin. Please go ahead and provide me with the list of texts for which you want me to determine the applicable labels.\n"
     ]
    }
   ],
   "source": [
    "conversation_history = [\n",
    "    {\"role\": \"system\", \"content\": \"Hello! How can I assist you today?\"}\n",
    "]\n",
    "\n",
    "prompt_template = (\n",
    "    \"You are a multi-label classifier tasked with finding all labels applicable to a product description. \"\n",
    "    \"For this, you will receive a list of labels. \"\n",
    "    \"Only include a label in your output if it could really be considered a category of the product description. \"\n",
    "    \"In the next prompt, I will provide you with a list of texts, and you should return a Python list of lists \"\n",
    "    \"with all applicable labels for each product description. If no labels apply to a product description, return an empty list ([]). \"\n",
    "    \"Provide your response as a Python list of lists with the results, where each inner list corresponds to the labels for each text provided, in the same order. \"\n",
    "    \"In your answer, ONLY return a Python list with the results, nothing else. \"\n",
    "    f\"Here are the possible labels:\\n{list_sub_categories}. \"\n",
    "    \"Are you ready to begin?\"\n",
    ")\n",
    "\n",
    "initial_prompt = prompt_template\n",
    "\n",
    "result = query_gpt_with_history(apikey, initial_prompt, conversation_history)\n",
    "result = result.choices[0].message.content\n",
    "conversation_history.append({\"role\": \"user\", \"content\": initial_prompt})\n",
    "conversation_history.append({\"role\": \"system\", \"content\": result})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "1a748c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 10%|█         | 1/10 [00:01<00:15,  1.68s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 20%|██        | 2/10 [00:04<00:19,  2.39s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 30%|███       | 3/10 [00:06<00:13,  1.99s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 40%|████      | 4/10 [00:07<00:10,  1.74s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 50%|█████     | 5/10 [00:09<00:08,  1.68s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 60%|██████    | 6/10 [00:11<00:08,  2.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 70%|███████   | 7/10 [00:14<00:06,  2.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 80%|████████  | 8/10 [00:16<00:04,  2.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 90%|█████████ | 9/10 [00:18<00:02,  2.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 10/10 [00:23<00:00,  2.34s/it]\n"
     ]
    }
   ],
   "source": [
    "texts = data['description'].tolist()[:50]\n",
    "\n",
    "batch_size = 5\n",
    "batches = [texts[i:i + batch_size] for i in range(0, len(texts), batch_size)]\n",
    "\n",
    "list_results = []\n",
    "\n",
    "for batch in tqdm(batches):\n",
    "\n",
    "    batch_prompt = (\n",
    "        f\"Here is the list of product descriptions: {batch}. \"\n",
    "        \"Please provide the applicable labels for each description.\"\n",
    "    )\n",
    "    result = query_gpt_with_history(apikey, batch_prompt, conversation_history)\n",
    "\n",
    "    try:\n",
    "        result_text = ast.literal_eval(result.choices[0].message.content)\n",
    "    except Exception as e:\n",
    "        result_text = [[] for _ in range(batch_size)]\n",
    "\n",
    "    if len(result_text) != len(batch):\n",
    "        result_text = [[] for _ in range(batch_size)]\n",
    "\n",
    "    list_results.extend(result_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2dc81447",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_example = data[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e4e29bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9824/413905904.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_example[\"labels_batch\"] = list_results\n"
     ]
    }
   ],
   "source": [
    "data_example[\"labels_batch\"] = list_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "bc5ade2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_example.to_excel(\"openai_annotation_example_4.xlsx\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafa3eed",
   "metadata": {},
   "source": [
    "# Zero shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "50273a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'Activity description: This museum has a vast collection of paintings and sculptures.', 'labels': ['History Museums: Historical artifacts, ancient civilizations, historical events, cultural heritage.'], 'scores': [0.7074357867240906]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "text = \"Activity description: This museum has a vast collection of paintings and sculptures.\"\n",
    "hypothesis_template = \"This activity description can belong to the category {}\"\n",
    "classes_verbalized = [\"History Museums: Historical artifacts, ancient civilizations, historical events, cultural heritage.\"]\n",
    "zeroshot_classifier = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/deberta-v3-large-zeroshot-v2.0\")\n",
    "output = zeroshot_classifier(text, classes_verbalized, hypothesis_template=hypothesis_template, multi_label=False)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0cc250",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
